┌─────────────────────────┐
│   Start Streamlit App   │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Load ENV variables      │
│ (OPENROUTER_API_KEY)    │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Initialize ChatOpenAI   │
│ (OpenRouter model)      │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Initialize Memory       │
│ (ConversationBuffer)   │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Render Streamlit UI     │
│ - Title                 │
│ - Text Input            │
│ - Button                │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ User enters question    │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ User clicks "Ask AI"    │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ system_prompts()        │
│ receives user input     │
└──────────┬──────────────┘
           ↓
      ┌─────▼─────┐
      │ Greeting? │──Yes──► Return greeting
      └─────┬─────┘
            │No
            ↓
┌─────────────────────────┐
│ Load previous chat      │
│ from memory             │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Build prompt            │
│ (history + question)   │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Send prompt to LLM      │
│ via OpenRouter          │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Receive AI response     │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Save (Q, A) in memory   │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Display AI answer       │
│ (ONLY latest answer)   │
└──────────┬──────────────┘
           ↓
┌─────────────────────────┐
│ Wait for next question  │
└─────────────────────────┘
